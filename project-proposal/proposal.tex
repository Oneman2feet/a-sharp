\documentclass{article}
\usepackage[top=1.2in, bottom=1in, left=2in, right=2in]{geometry}
\usepackage{enumerate, multicol}
\usepackage{amsmath}
\usepackage{parskip}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

\begin{titlepage}
\begin{center}

\textsc{\LARGE Cornell University}\\[1.5cm]

\textsc{\Large CS 4621 Practicum Project Proposal}\\[0.5cm]

% Title
\HRule \\[0.4cm]
{ \huge \bfseries A$\sharp$ -- Music Visualizer \\[0.4cm] }

\HRule \\[1.5cm]

% Group members
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
Shane \textsc{Moore} \\
\emph{swm85}
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
Zachary \textsc{Zimmerman} \\
\emph{ztz3}
\end{flushright}
\end{minipage}
\par\vspace{0.5cm}
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
Emre \textsc{Findik} \\
\emph{ef343}
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
Joseph \textsc{Vinegrad} \\
\emph{jav86}
\end{flushright}
\end{minipage}

\vfill

% Bottom of the page
{\large October 9, 2014}

\end{center}

\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Summary}

Our group proposes to create a music visualizer called A$\sharp$ (A Sharp) which goes beyond the interpretive scope of current visualization software.  We find that the typical music visualization does fine at looking good alongside the music, but fails to go beyond and provide actual interpretation or insight into the song.

As Edward Tufte said in his book \textit{The Visual Display of Quantitative Information}, ``At their best, graphics are instruments for reasoning about quantitative information'' (Introduction).  The job of a music visualizer, therefore, is to provide the user with enough relevant and useful visual information that they may interpret, on a higher level, the characteristics of the sound which is being visualized.  If possible, the visualization could be considered a summary of the song, or even a rudimentary alternative.  We plan to work towards this standard in our music visualizer, A$\sharp$.

\section{Software description}

The software we are planning to create will output a video file, given an audio file input. The visuals in the video file will be built upon not only instantaneous properties of the audio but will also be dependent upon qualities such as tempo, rhythm progressions and the musical genre, which requires analyses of the audio as a whole or in greater parts. Each of these audio qualities will be linked to a specific visual quality in the video file, such as the color properties (hue, saturation etc.) and the output shape.

\section{Application in Graphics}

The graphics portion of our project will focus primarily on rendering and animation.
 
Given our goal of creating complex visual displays that accurately reflect different types of music, rendering will be a key component of our work. We will likely want to incorporate a variety of shapes, textures, and lighting. In order to accomplish this, we will apply techniques such as texture mapping and shading (under various models). Additionally, our scenes will probably consist of several objects on the screen simultaneously. To account for this, we will need to use ray tracing techniques to determine relative positions of objects. Still, determining what combination of objects and shading models to use for different songs remains a challenge.
 
Animation is another major area of focus for our project, as we aim to produce a dynamic moving display for our visualizer. To enhance the design and versatility of our visualizer, we will utilize different animation patterns corresponding to different types of music. To implement these, we will apply techniques related to both linear and nonlinear transformations (in 2D and 3D), as well as optimizations for seamlessly animating frame by frame. While we haven't yet discussed animation in class, we are scheduled to do so shortly before our first milestone, giving us time to incorporate animation techniques thereafter.

\section{Properties of Music for Quantification}

\begin{itemize}
	\item Song genre
	\item Amplitude at a given frequency
	\item Sound location (stereo)
	\item Sound quality (Hilbert scope)
	\item Tremolo
	\item Centroid, spread, skewness and kurtosis (of an amplitude envelope)
	\item Mel-frequency cepstrum
	\item Rhythm complexity
	\item Distinguish accompaniment from melody
	\item Melody: pitch, volume, position in chord
\end{itemize}

\section{Software Architecture}

Our code will be broken up into four modules, which each represent a specific part of the program. They are laid out as follows: \\

\begin{enumerate}
	\item Data collection / statistical analysis (input $\rightarrow$ data)
	\begin{itemize}
		\item Takes in sound file
		\item Runs library calls for music analysis
		\item Returns the results of all analyses in the formats of the respective libraries
	\end{itemize}
	\item Data formatting (data $\rightarrow$ models)
	\begin{itemize}
		\item Takes in the raw analysis data
		\item Formats it all in a sensible way
		\item Returns the data in the cleaner protocol
	\end{itemize}
	\item Data interpretation (controller: models $\rightarrow$ views)
	\begin{itemize}
		\item Takes in the clean data
		\item Interprets it in new (i.e. unique to our project) ways
		\item Returns a property-based representation of the visualization
	\end{itemize}
	\item Rendering (views $\rightarrow$ output)
	\begin{itemize}
		\item Takes in the parameters of the visualization
		\item Creates the scene based on these parameters given
		\item Animates based on the parameters with respect to time
		\item Returns the video
	\end{itemize}
\end{enumerate}

The first module will perform some primary analyzation of the sound file that's been passed to the software. This will include attempts to determine the key and tempo of the piece, variations (and base-levels) of volume, and spectral analysis for some understanding of the instrumentation being used. Data from the analysis will be stored in the next module; a series of models that will be designed for fast access and calculations necessary for our representations of the piece.
	A controller will act as an interface between the models and views, which will store data about the visual representation itself. A final module, the renderer, will take these software representations of the animation (the views), and produce a video to accompany the song.

We plan on using python for coding this project, with a few third-party libraries for the sound analysis module.

\section{Work Distribution}

\paragraph{Emre:} Sound file analysis (\oldstylenums{1}) and model for representation of sound (\oldstylenums{2})
\vspace{-0.5cm}
\paragraph{Shane:} Model design (\oldstylenums{2}) and controllers (\oldstylenums{3})
\vspace{-0.5cm}
\paragraph{Zachary:} Sound data interpretation (\oldstylenums{3}) and visualization design (\oldstylenums{4})
\vspace{-0.5cm}
\paragraph{Joey:} Graphical representation of the view and rendering (\oldstylenums{4})

\section{Milestone}

By the milestone, our group hopes to have the following as part of a proof of concept:

\begin{itemize}
	\item Warmup: midi support, later on, wav support
	\item Working interfaces for each of the sound libraries we choose to use
	\item Integration of data from all of the libraries into one format
	\item A rudimentary visual representing every meaningful piece of insight we can glean from the music
\end{itemize}

\end{document}
